{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-family: Arial, sans-serif; color:#01afff\">Logistic Regression</span>\n",
    "## <span style=\"font-family: Arial, sans-serif; color:navyblue\">Comparing models with raw and WOE inputs</span>\n",
    "\n",
    "Author: https://www.github.com/deburky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fetch blended credit data\n",
    "url = (\n",
    "    \"https://drive.google.com/file/d/1Is8UZnPRExI-SLJMle8GRbFGpha5IvYZ/view?usp=sharing\"\n",
    ")\n",
    "url = \"https://drive.google.com/uc?id=\" + url.split(\"/\")[-2]\n",
    "dataset = pd.read_csv(url, index_col=False)\n",
    "\n",
    "features = [\n",
    "    \"revolving_utilization_of_unsecured_lines\",\n",
    "    \"account_never_delinq_percent\",\n",
    "    \"net_fraction_revolving_burden\",\n",
    "    \"external_risk_estimate\",\n",
    "    \"num_total_cc_accounts\",\n",
    "    \"average_months_in_file\",\n",
    "]\n",
    "\n",
    "target = 'is_bad'\n",
    "\n",
    "X, y = dataset[features], dataset[target]\n",
    "\n",
    "ix_train, ix_test = train_test_split(\n",
    "    X.index, stratify=y, test_size=0.3, random_state=62\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw inputs\n",
    "\n",
    "Here we use raw numerical data to fit a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Fisher Scoring Iterations...\n",
      "Iteration: 1, Log Loss: 0.6931\n",
      "Iteration: 2, Log Loss: 0.2799\n",
      "Iteration: 3, Log Loss: 0.2231\n",
      "Iteration: 4, Log Loss: 0.2096\n",
      "Iteration: 5, Log Loss: 0.2080\n",
      "Maximum iterations reached without convergence.\n",
      "Coefficients: [[ 5.8040147   2.87241899 -0.09790921  0.02463083 -0.01566946  0.03816645\n",
      "  -0.00896689]]\n",
      "Probability of bias: 99.70%\n",
      "Gini (test): 79.74%\n",
      "Log loss (test): 0.21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭── Fisher Scoring Logistic Regression Fit ──╮\n",
       "│                                            │\n",
       "│         Total Fisher Scoring Iterations: <span style=\"color: #00afff; text-decoration-color: #00afff\">5</span> │\n",
       "│         Log Likelihood: <span style=\"color: #00afff; text-decoration-color: #00afff\">-1456.2238</span>         │\n",
       "│         Beta 0 = intercept (bias): <span style=\"color: #00afff; text-decoration-color: #00afff\">True</span>    │\n",
       "│                                            │\n",
       "╰────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭── Fisher Scoring Logistic Regression Fit ──╮\n",
       "│                                            │\n",
       "│         Total Fisher Scoring Iterations: \u001b[38;5;39m5\u001b[0m │\n",
       "│         Log Likelihood: \u001b[38;5;39m-1456.2238\u001b[0m         │\n",
       "│         Beta 0 = intercept (bias): \u001b[38;5;39mTrue\u001b[0m    │\n",
       "│                                            │\n",
       "╰────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                    Fisher Scoring Logistic Regression Summary                                     </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">                                          </span>┃<span style=\"font-weight: bold\">          </span>┃<span style=\"font-weight: bold\">            </span>┃<span style=\"font-weight: bold\"> Wald         </span>┃<span style=\"font-weight: bold\">         </span>┃<span style=\"font-weight: bold\">          </span>┃<span style=\"font-weight: bold\">          </span>┃\n",
       "┃<span style=\"font-weight: bold\">                                Parameter </span>┃<span style=\"font-weight: bold\"> Estimate </span>┃<span style=\"font-weight: bold\"> Std. Error </span>┃<span style=\"font-weight: bold\"> Statistic    </span>┃<span style=\"font-weight: bold\"> P-value </span>┃<span style=\"font-weight: bold\"> Lower CI </span>┃<span style=\"font-weight: bold\"> Upper CI </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━┩\n",
       "│<span style=\"color: #00afff; text-decoration-color: #00afff\">                         intercept (bias) </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 5.8040   </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 0.4104     </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 14.1420      </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 0.0000  </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 4.9996   </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 6.6084   </span>│\n",
       "│<span style=\"color: #00afff; text-decoration-color: #00afff\"> revolving_utilization_of_unsecured_lines </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 2.8724   </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 0.1329     </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 21.6085      </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 0.0000  </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 2.6119   </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 3.1330   </span>│\n",
       "│<span style=\"color: #00afff; text-decoration-color: #00afff\">             account_never_delinq_percent </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> -0.0979  </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 0.0044     </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> -22.3834     </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 0.0000  </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> -0.1065  </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> -0.0893  </span>│\n",
       "│<span style=\"color: #00afff; text-decoration-color: #00afff\">            net_fraction_revolving_burden </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 0.0246   </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 0.0016     </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 15.1367      </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 0.0000  </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 0.0214   </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 0.0278   </span>│\n",
       "│<span style=\"color: #00afff; text-decoration-color: #00afff\">                   external_risk_estimate </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> -0.0157  </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 0.0027     </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> -5.8525      </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 0.0000  </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> -0.0209  </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> -0.0104  </span>│\n",
       "│<span style=\"color: #00afff; text-decoration-color: #00afff\">                    num_total_cc_accounts </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 0.0382   </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 0.0056     </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 6.7670       </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 0.0000  </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 0.0271   </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 0.0492   </span>│\n",
       "│<span style=\"color: #00afff; text-decoration-color: #00afff\">                   average_months_in_file </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> -0.0090  </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 0.0017     </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> -5.2164      </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> 0.0000  </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> -0.0123  </span>│<span style=\"color: #00afff; text-decoration-color: #00afff\"> -0.0056  </span>│\n",
       "└──────────────────────────────────────────┴──────────┴────────────┴──────────────┴─────────┴──────────┴──────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                    Fisher Scoring Logistic Regression Summary                                     \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┓\n",
       "┃\u001b[1m                                          \u001b[0m┃\u001b[1m          \u001b[0m┃\u001b[1m            \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mWald        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m         \u001b[0m┃\u001b[1m          \u001b[0m┃\u001b[1m          \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m                               Parameter\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mEstimate\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mStd. Error\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mStatistic   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mP-value\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mLower CI\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper CI\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━┩\n",
       "│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m                        intercept (bias)\u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m5.8040  \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m0.4104    \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m14.1420     \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m0.0000 \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m4.9996  \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m6.6084  \u001b[0m\u001b[38;5;39m \u001b[0m│\n",
       "│\u001b[38;5;39m \u001b[0m\u001b[38;5;39mrevolving_utilization_of_unsecured_lines\u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m2.8724  \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m0.1329    \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m21.6085     \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m0.0000 \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m2.6119  \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m3.1330  \u001b[0m\u001b[38;5;39m \u001b[0m│\n",
       "│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m            account_never_delinq_percent\u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m-0.0979 \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m0.0044    \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m-22.3834    \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m0.0000 \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m-0.1065 \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m-0.0893 \u001b[0m\u001b[38;5;39m \u001b[0m│\n",
       "│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m           net_fraction_revolving_burden\u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m0.0246  \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m0.0016    \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m15.1367     \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m0.0000 \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m0.0214  \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m0.0278  \u001b[0m\u001b[38;5;39m \u001b[0m│\n",
       "│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m                  external_risk_estimate\u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m-0.0157 \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m0.0027    \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m-5.8525     \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m0.0000 \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m-0.0209 \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m-0.0104 \u001b[0m\u001b[38;5;39m \u001b[0m│\n",
       "│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m                   num_total_cc_accounts\u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m0.0382  \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m0.0056    \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m6.7670      \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m0.0000 \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m0.0271  \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m0.0492  \u001b[0m\u001b[38;5;39m \u001b[0m│\n",
       "│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m                  average_months_in_file\u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m-0.0090 \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m0.0017    \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m-5.2164     \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m0.0000 \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m-0.0123 \u001b[0m\u001b[38;5;39m \u001b[0m│\u001b[38;5;39m \u001b[0m\u001b[38;5;39m-0.0056 \u001b[0m\u001b[38;5;39m \u001b[0m│\n",
       "└──────────────────────────────────────────┴──────────┴────────────┴──────────────┴─────────┴──────────┴──────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fisher_scoring import FisherScoringLogisticRegression\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "model = FisherScoringLogisticRegression(use_bias=True, information='expected', max_iter=5, verbose=True)\n",
    "model.fit(X.loc[ix_train, :], y[ix_train])\n",
    "\n",
    "# Extract model weights and calculate Gini coefficient\n",
    "model_weights = model.beta.T\n",
    "print(f\"Coefficients: {model_weights}\")\n",
    "\n",
    "p_of_bias = sigmoid(model_weights[:, 0]).flatten().item()\n",
    "print(f\"Probability of bias: {p_of_bias:.2%}\")\n",
    "\n",
    "predictions = model.predict_proba(X.loc[ix_test, :])[:, 1]\n",
    "gini = 2 * roc_auc_score(y[ix_test], predictions) - 1\n",
    "print(f\"Gini (test): {gini:.2%}\")\n",
    "\n",
    "log_loss_score = log_loss(y[ix_test], predictions)\n",
    "print(f\"Log loss (test): {log_loss_score:.2f}\")\n",
    "\n",
    "# Display the summary of the model\n",
    "model.display_summary(style='deep_sky_blue1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini (test): 79.73%\n",
      "Intercept: [5.78775471]\n",
      "Coefficients: [[ 2.87751276 -0.09778669  0.02464418 -0.01564931  0.03816656 -0.00897061]]\n",
      "Probability of bias: 99.69%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "sk_model = LogisticRegression(solver='newton-cg', penalty=None)\n",
    "sk_model.fit(X.loc[ix_train, :], y[ix_train])\n",
    "\n",
    "sk_predictions = sk_model.predict_proba(X.loc[ix_test, :])[:, 1]\n",
    "sk_gini = 2 * roc_auc_score(y[ix_test], sk_predictions) - 1\n",
    "print(f\"Gini (test): {sk_gini:.2%}\")\n",
    "\n",
    "# Print intercept and coefficients\n",
    "print(f\"Intercept: {sk_model.intercept_}\")\n",
    "print(f\"Coefficients: {sk_model.coef_}\")\n",
    "\n",
    "p_of_bias = sigmoid(sk_model.intercept_).flatten().item()\n",
    "print(f\"Probability of bias: {p_of_bias:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WOE inputs\n",
    "\n",
    "Weight of Evidence (WOE) converts numerical ranges to a set of discrete categories each containing a log likelihood ratio. \n",
    "\n",
    "The value of WOE tells us how likely the data (evidence) supports the hypothesis (e.g., default or no default).\n",
    "\n",
    "In the traditional credit scoring methodology, the coefficients are expected to be negative due to the formula applied to feature bins:\n",
    "\n",
    "$P(X=x_i|Y=0)/P(X=x_i|Y=1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WOE via conditional probabilities (OptBinning)\n",
    "\n",
    "We use [**OptBinning**](https://gnpalencia.org/optbinning/index.html) library for preprocessing inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Sep 28 08:18:48 PM: Encountered unexpected exception importing solver GLOP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.10.4067). Expected < 9.10.0. Please open a feature request on cvxpy to enable support for this version.')\n",
      "(CVXPY) Sep 28 08:18:48 PM: Encountered unexpected exception importing solver PDLP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.10.4067). Expected < 9.10.0. Please open a feature request on cvxpy to enable support for this version.')\n",
      "Starting Fisher Scoring Iterations...\n",
      "Iteration: 1, Log Loss: 0.6931\n",
      "Iteration: 2, Log Loss: 0.2724\n",
      "Iteration: 3, Log Loss: 0.2002\n",
      "Iteration: 4, Log Loss: 0.1740\n",
      "Iteration: 5, Log Loss: 0.1665\n",
      "Iteration: 6, Log Loss: 0.1654\n",
      "Iteration: 7, Log Loss: 0.1653\n",
      "Iteration: 8, Log Loss: 0.1653\n",
      "Iteration: 9, Log Loss: 0.1653\n",
      "Iteration: 10, Log Loss: 0.1653\n",
      "Convergence reached after 10 iterations.\n",
      "Coefficients: [[-2.25705117 -1.01248996 -1.02589516 -0.39071063 -0.77812967 -1.25793343\n",
      "  -0.45646565]]\n",
      "Gini (test): 88.30%\n",
      "Log loss (test): 0.17\n",
      "Probability of bias: 9.47%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭── Fisher Scoring Logistic Regression Fit ───╮\n",
       "│                                             │\n",
       "│         Total Fisher Scoring Iterations: <span style=\"color: #8787ff; text-decoration-color: #8787ff\">10</span> │\n",
       "│         Log Likelihood: <span style=\"color: #8787ff; text-decoration-color: #8787ff\">-1157.3816</span>          │\n",
       "│         Beta 0 = intercept (bias): <span style=\"color: #8787ff; text-decoration-color: #8787ff\">True</span>     │\n",
       "│                                             │\n",
       "╰─────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭── Fisher Scoring Logistic Regression Fit ───╮\n",
       "│                                             │\n",
       "│         Total Fisher Scoring Iterations: \u001b[38;5;105m10\u001b[0m │\n",
       "│         Log Likelihood: \u001b[38;5;105m-1157.3816\u001b[0m          │\n",
       "│         Beta 0 = intercept (bias): \u001b[38;5;105mTrue\u001b[0m     │\n",
       "│                                             │\n",
       "╰─────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                    Fisher Scoring Logistic Regression Summary                                     </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">                                          </span>┃<span style=\"font-weight: bold\">          </span>┃<span style=\"font-weight: bold\">            </span>┃<span style=\"font-weight: bold\"> Wald         </span>┃<span style=\"font-weight: bold\">         </span>┃<span style=\"font-weight: bold\">          </span>┃<span style=\"font-weight: bold\">          </span>┃\n",
       "┃<span style=\"font-weight: bold\">                                Parameter </span>┃<span style=\"font-weight: bold\"> Estimate </span>┃<span style=\"font-weight: bold\"> Std. Error </span>┃<span style=\"font-weight: bold\"> Statistic    </span>┃<span style=\"font-weight: bold\"> P-value </span>┃<span style=\"font-weight: bold\"> Lower CI </span>┃<span style=\"font-weight: bold\"> Upper CI </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━┩\n",
       "│<span style=\"color: #8787ff; text-decoration-color: #8787ff\">                         intercept (bias) </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -2.2571  </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> 0.0727     </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -31.0343     </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> 0.0000  </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -2.3996  </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -2.1145  </span>│\n",
       "│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> revolving_utilization_of_unsecured_lines </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -1.0125  </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> 0.0515     </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -19.6430     </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> 0.0000  </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -1.1135  </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -0.9115  </span>│\n",
       "│<span style=\"color: #8787ff; text-decoration-color: #8787ff\">             account_never_delinq_percent </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -1.0259  </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> 0.0523     </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -19.6299     </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> 0.0000  </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -1.1283  </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -0.9235  </span>│\n",
       "│<span style=\"color: #8787ff; text-decoration-color: #8787ff\">            net_fraction_revolving_burden </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -0.3907  </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> 0.0846     </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -4.6192      </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> 0.0000  </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -0.5565  </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -0.2249  </span>│\n",
       "│<span style=\"color: #8787ff; text-decoration-color: #8787ff\">                   external_risk_estimate </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -0.7781  </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> 0.0718     </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -10.8446     </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> 0.0000  </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -0.9188  </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -0.6375  </span>│\n",
       "│<span style=\"color: #8787ff; text-decoration-color: #8787ff\">                    num_total_cc_accounts </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -1.2579  </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> 0.2734     </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -4.6011      </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> 0.0000  </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -1.7938  </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -0.7221  </span>│\n",
       "│<span style=\"color: #8787ff; text-decoration-color: #8787ff\">                   average_months_in_file </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -0.4565  </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> 0.0987     </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -4.6266      </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> 0.0000  </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -0.6498  </span>│<span style=\"color: #8787ff; text-decoration-color: #8787ff\"> -0.2631  </span>│\n",
       "└──────────────────────────────────────────┴──────────┴────────────┴──────────────┴─────────┴──────────┴──────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                    Fisher Scoring Logistic Regression Summary                                     \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┓\n",
       "┃\u001b[1m                                          \u001b[0m┃\u001b[1m          \u001b[0m┃\u001b[1m            \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mWald        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m         \u001b[0m┃\u001b[1m          \u001b[0m┃\u001b[1m          \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m                               Parameter\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mEstimate\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mStd. Error\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mStatistic   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mP-value\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mLower CI\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper CI\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━┩\n",
       "│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m                        intercept (bias)\u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-2.2571 \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m0.0727    \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-31.0343    \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m0.0000 \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-2.3996 \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-2.1145 \u001b[0m\u001b[38;5;105m \u001b[0m│\n",
       "│\u001b[38;5;105m \u001b[0m\u001b[38;5;105mrevolving_utilization_of_unsecured_lines\u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-1.0125 \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m0.0515    \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-19.6430    \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m0.0000 \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-1.1135 \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-0.9115 \u001b[0m\u001b[38;5;105m \u001b[0m│\n",
       "│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m            account_never_delinq_percent\u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-1.0259 \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m0.0523    \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-19.6299    \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m0.0000 \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-1.1283 \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-0.9235 \u001b[0m\u001b[38;5;105m \u001b[0m│\n",
       "│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m           net_fraction_revolving_burden\u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-0.3907 \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m0.0846    \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-4.6192     \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m0.0000 \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-0.5565 \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-0.2249 \u001b[0m\u001b[38;5;105m \u001b[0m│\n",
       "│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m                  external_risk_estimate\u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-0.7781 \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m0.0718    \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-10.8446    \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m0.0000 \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-0.9188 \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-0.6375 \u001b[0m\u001b[38;5;105m \u001b[0m│\n",
       "│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m                   num_total_cc_accounts\u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-1.2579 \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m0.2734    \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-4.6011     \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m0.0000 \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-1.7938 \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-0.7221 \u001b[0m\u001b[38;5;105m \u001b[0m│\n",
       "│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m                  average_months_in_file\u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-0.4565 \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m0.0987    \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-4.6266     \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m0.0000 \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-0.6498 \u001b[0m\u001b[38;5;105m \u001b[0m│\u001b[38;5;105m \u001b[0m\u001b[38;5;105m-0.2631 \u001b[0m\u001b[38;5;105m \u001b[0m│\n",
       "└──────────────────────────────────────────┴──────────┴────────────┴──────────────┴─────────┴──────────┴──────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from optbinning import BinningProcess\n",
    "from fisher_scoring import FisherScoringLogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "# Create the binning process and logistic model pipeline\n",
    "binning_process = BinningProcess(variable_names=features, categorical_variables=[])\n",
    "model = FisherScoringLogisticRegression(use_bias=True, information='expected', verbose=True)\n",
    "\n",
    "woe_logistic_model = make_pipeline(binning_process, model)\n",
    "woe_logistic_model.fit(X.loc[ix_train, :], y[ix_train])\n",
    "\n",
    "# Extract model weights and calculate Gini coefficient\n",
    "model_weights = woe_logistic_model[-1].beta.T\n",
    "print(f\"Coefficients: {model_weights}\")\n",
    "\n",
    "predictions = woe_logistic_model.predict_proba(X.loc[ix_test, :])[:, 1]\n",
    "gini = 2 * roc_auc_score(y[ix_test], predictions) - 1\n",
    "print(f\"Gini (test): {gini:.2%}\")\n",
    "\n",
    "log_loss_score = log_loss(y[ix_test], predictions)\n",
    "print(f\"Log loss (test): {log_loss_score:.2f}\")\n",
    "\n",
    "p_of_bias = sigmoid(model_weights[:, 0]).flatten().item()\n",
    "print(f\"Probability of bias: {p_of_bias:.2%}\")\n",
    "\n",
    "# Display the summary of the model\n",
    "woe_logistic_model[-1].display_summary(style='light_slate_blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WOE via Bayes factor (custom)\n",
    "\n",
    "This is an approach based on the Turing-Good Bayes factor. This differs from the conventional WOE calculation with conditional probabilities in that we use target encoder derive WOE from probabilities in relation to average event rate and its complement.\n",
    "\n",
    "We use a custom scikit-learn implementation to show this approach in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import (\n",
    "    KBinsDiscretizer,\n",
    "    TargetEncoder,\n",
    "    FunctionTransformer\n",
    ")\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.special import logit\n",
    "\n",
    "base_log_odds = np.log(\n",
    "    np.mean(y.loc[ix_train]) \n",
    "    / (1 - np.mean(y.loc[ix_train]))\n",
    ")\n",
    "\n",
    "def convert_to_woe(X: pd.DataFrame):\n",
    "    eps = 1e-8\n",
    "    X_log_odds = logit(X + eps)\n",
    "    X_woe = base_log_odds - X_log_odds # negate WOE for scoring\n",
    "    return pd.DataFrame(X_woe, columns=X.columns, index=X.index)\n",
    "\n",
    "# Ensure the pipeline maintains DataFrames with their feature names\n",
    "bayes_factor_encoder = make_pipeline(\n",
    "    KBinsDiscretizer(n_bins=10, encode=\"ordinal\", strategy=\"kmeans\").set_output(transform='pandas'),\n",
    "    TargetEncoder(smooth=1e-0, cv=5).set_output(transform='pandas'),\n",
    "    FunctionTransformer(convert_to_woe, validate=False, feature_names_out='one-to-one')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Fisher Scoring Iterations...\n",
      "Iteration: 1, Log Loss: 0.6931\n",
      "Iteration: 2, Log Loss: 0.2732\n",
      "Iteration: 3, Log Loss: 0.2034\n",
      "Iteration: 4, Log Loss: 0.1798\n",
      "Iteration: 5, Log Loss: 0.1742\n",
      "Iteration: 6, Log Loss: 0.1736\n",
      "Iteration: 7, Log Loss: 0.1736\n",
      "Maximum iterations reached without convergence.\n",
      "Coefficients: [[-2.19433421 -1.02561293 -1.00022244 -0.3158842  -0.8153639  -0.81020418\n",
      "  -0.63188525]]\n",
      "Gini (test): 88.30%\n",
      "Log loss (test): 0.17\n",
      "Probability of bias: 10.03%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭── Fisher Scoring Logistic Regression Fit ──╮\n",
       "│                                            │\n",
       "│         Total Fisher Scoring Iterations: <span style=\"color: #ff005f; text-decoration-color: #ff005f\">7</span> │\n",
       "│         Log Likelihood: <span style=\"color: #ff005f; text-decoration-color: #ff005f\">-1215.3439</span>         │\n",
       "│         Beta 0 = intercept (bias): <span style=\"color: #ff005f; text-decoration-color: #ff005f\">True</span>    │\n",
       "│                                            │\n",
       "╰────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭── Fisher Scoring Logistic Regression Fit ──╮\n",
       "│                                            │\n",
       "│         Total Fisher Scoring Iterations: \u001b[38;5;197m7\u001b[0m │\n",
       "│         Log Likelihood: \u001b[38;5;197m-1215.3439\u001b[0m         │\n",
       "│         Beta 0 = intercept (bias): \u001b[38;5;197mTrue\u001b[0m    │\n",
       "│                                            │\n",
       "╰────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                    Fisher Scoring Logistic Regression Summary                                     </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">                                          </span>┃<span style=\"font-weight: bold\">          </span>┃<span style=\"font-weight: bold\">            </span>┃<span style=\"font-weight: bold\"> Wald         </span>┃<span style=\"font-weight: bold\">         </span>┃<span style=\"font-weight: bold\">          </span>┃<span style=\"font-weight: bold\">          </span>┃\n",
       "┃<span style=\"font-weight: bold\">                                Parameter </span>┃<span style=\"font-weight: bold\"> Estimate </span>┃<span style=\"font-weight: bold\"> Std. Error </span>┃<span style=\"font-weight: bold\"> Statistic    </span>┃<span style=\"font-weight: bold\"> P-value </span>┃<span style=\"font-weight: bold\"> Lower CI </span>┃<span style=\"font-weight: bold\"> Upper CI </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━┩\n",
       "│<span style=\"color: #ff005f; text-decoration-color: #ff005f\">                         intercept (bias) </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -2.1943  </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> 0.0652     </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -33.6436     </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> 0.0000  </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -2.3222  </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -2.0665  </span>│\n",
       "│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> revolving_utilization_of_unsecured_lines </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -1.0256  </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> 0.0514     </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -19.9594     </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> 0.0000  </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -1.1263  </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -0.9249  </span>│\n",
       "│<span style=\"color: #ff005f; text-decoration-color: #ff005f\">             account_never_delinq_percent </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -1.0002  </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> 0.0464     </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -21.5550     </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> 0.0000  </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -1.0912  </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -0.9093  </span>│\n",
       "│<span style=\"color: #ff005f; text-decoration-color: #ff005f\">            net_fraction_revolving_burden </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -0.3159  </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> 0.0884     </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -3.5715      </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> 0.0004  </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -0.4892  </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -0.1425  </span>│\n",
       "│<span style=\"color: #ff005f; text-decoration-color: #ff005f\">                   external_risk_estimate </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -0.8154  </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> 0.0637     </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -12.7950     </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> 0.0000  </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -0.9403  </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -0.6905  </span>│\n",
       "│<span style=\"color: #ff005f; text-decoration-color: #ff005f\">                    num_total_cc_accounts </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -0.8102  </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> 0.3012     </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -2.6899      </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> 0.0071  </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -1.4006  </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -0.2199  </span>│\n",
       "│<span style=\"color: #ff005f; text-decoration-color: #ff005f\">                   average_months_in_file </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -0.6319  </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> 0.0959     </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -6.5884      </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> 0.0000  </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -0.8199  </span>│<span style=\"color: #ff005f; text-decoration-color: #ff005f\"> -0.4439  </span>│\n",
       "└──────────────────────────────────────────┴──────────┴────────────┴──────────────┴─────────┴──────────┴──────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                    Fisher Scoring Logistic Regression Summary                                     \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┓\n",
       "┃\u001b[1m                                          \u001b[0m┃\u001b[1m          \u001b[0m┃\u001b[1m            \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mWald        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m         \u001b[0m┃\u001b[1m          \u001b[0m┃\u001b[1m          \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m                               Parameter\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mEstimate\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mStd. Error\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mStatistic   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mP-value\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mLower CI\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUpper CI\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━┩\n",
       "│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m                        intercept (bias)\u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-2.1943 \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m0.0652    \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-33.6436    \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m0.0000 \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-2.3222 \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-2.0665 \u001b[0m\u001b[38;5;197m \u001b[0m│\n",
       "│\u001b[38;5;197m \u001b[0m\u001b[38;5;197mrevolving_utilization_of_unsecured_lines\u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-1.0256 \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m0.0514    \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-19.9594    \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m0.0000 \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-1.1263 \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-0.9249 \u001b[0m\u001b[38;5;197m \u001b[0m│\n",
       "│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m            account_never_delinq_percent\u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-1.0002 \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m0.0464    \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-21.5550    \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m0.0000 \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-1.0912 \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-0.9093 \u001b[0m\u001b[38;5;197m \u001b[0m│\n",
       "│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m           net_fraction_revolving_burden\u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-0.3159 \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m0.0884    \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-3.5715     \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m0.0004 \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-0.4892 \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-0.1425 \u001b[0m\u001b[38;5;197m \u001b[0m│\n",
       "│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m                  external_risk_estimate\u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-0.8154 \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m0.0637    \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-12.7950    \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m0.0000 \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-0.9403 \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-0.6905 \u001b[0m\u001b[38;5;197m \u001b[0m│\n",
       "│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m                   num_total_cc_accounts\u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-0.8102 \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m0.3012    \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-2.6899     \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m0.0071 \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-1.4006 \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-0.2199 \u001b[0m\u001b[38;5;197m \u001b[0m│\n",
       "│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m                  average_months_in_file\u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-0.6319 \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m0.0959    \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-6.5884     \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m0.0000 \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-0.8199 \u001b[0m\u001b[38;5;197m \u001b[0m│\u001b[38;5;197m \u001b[0m\u001b[38;5;197m-0.4439 \u001b[0m\u001b[38;5;197m \u001b[0m│\n",
       "└──────────────────────────────────────────┴──────────┴────────────┴──────────────┴─────────┴──────────┴──────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from optbinning import BinningProcess\n",
    "from fisher_scoring import FisherScoringLogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "# Create the binning process and logistic model pipeline\n",
    "model = FisherScoringLogisticRegression(use_bias=True, information='expected', max_iter=7, verbose=True)\n",
    "\n",
    "woe_logistic_model = make_pipeline(bayes_factor_encoder, model)\n",
    "woe_logistic_model.fit(X.loc[ix_train, :], y[ix_train])\n",
    "\n",
    "# Extract model weights and calculate Gini coefficient\n",
    "model_weights = woe_logistic_model[-1].beta.T\n",
    "print(f\"Coefficients: {model_weights}\")\n",
    "\n",
    "predictions = woe_logistic_model.predict_proba(X.loc[ix_test, :])[:, 1]\n",
    "gini = 2 * roc_auc_score(y[ix_test], predictions) - 1\n",
    "print(f\"Gini (test): {gini:.2%}\")\n",
    "\n",
    "log_loss_score = log_loss(y[ix_test], predictions)\n",
    "print(f\"Log loss (test): {log_loss_score:.2f}\")\n",
    "\n",
    "p_of_bias = sigmoid(model_weights[:, 0]).flatten().item()\n",
    "print(f\"Probability of bias: {p_of_bias:.2%}\")\n",
    "\n",
    "# Display the summary of the model\n",
    "woe_logistic_model[-1].display_summary(style='deep_pink2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
