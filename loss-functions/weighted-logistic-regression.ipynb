{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <span style=\"font-family: Virgil GS, sans-serif; color:#97f788\">Logistic Regression</span> </center>\n",
    "## <center> <span style=\"font-family: Virgil GS, sans-serif; color:navyblue\">Weighted Log-Likelihood</span> </center>\n",
    "\n",
    " <span style=\"font-family: Virgil GS, sans-serif; color:navyblue\">Author: <a href=\"https://github.com/deburky\" title=\"GitHub link\">https://github.com/deburky</a></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fetch blended credit data\n",
    "url = (\n",
    "    \"https://drive.google.com/file/d/1Is8UZnPRExI-SLJMle8GRbFGpha5IvYZ/view?usp=sharing\"\n",
    ")\n",
    "url = \"https://drive.google.com/uc?id=\" + url.split(\"/\")[-2]\n",
    "dataset = pd.read_csv(url, index_col=False)\n",
    "\n",
    "features = [\n",
    "    \"revolving_utilization_of_unsecured_lines\",\n",
    "    \"account_never_delinq_percent\",\n",
    "    \"net_fraction_revolving_burden\",\n",
    "    \"num_total_cc_accounts\",\n",
    "    \"average_months_in_file\",\n",
    "    \"balance\"\n",
    "]\n",
    "\n",
    "target = 'is_bad'\n",
    "\n",
    "X, y = dataset[features], dataset[target]\n",
    "\n",
    "ix_train, ix_test = train_test_split(\n",
    "    X.index, stratify=y, test_size=0.3, random_state=62\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, class_weight={0: 1, 1: 1})\n",
    "\n",
    "model.fit(X.loc[ix_train], y.loc[ix_train])\n",
    "avg_pred = model.predict_proba(X.loc[ix_test])[:, 1].mean()\n",
    "print(f\"Mean predicted probability: {avg_pred:.2%}\")\n",
    "\n",
    "preds = model.predict_proba(X.loc[ix_test])[:, 1]\n",
    "gini = roc_auc_score(y.loc[ix_test], preds) * 2 - 1\n",
    "print(f\"Gini: {gini:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy.special import logit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import ks_2samp\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams.update({\"font.size\": 12})\n",
    "\n",
    "weights = []\n",
    "sns.set_style('white')\n",
    "\n",
    "def ks_stat(y, yhat):\n",
    "    return ks_2samp(yhat[y == 1], yhat[y != 1]).statistic # type: ignore\n",
    "\n",
    "def plot_densities(model, X, y, sample_weight, model_type=\"logistic\", class_to_weight=\"pos\"):\n",
    "    for sample_w in sample_weight:\n",
    "        if model_type == \"gbdt\":\n",
    "            model = xgb.XGBClassifier(\n",
    "                n_estimators=300,\n",
    "                max_depth=2,\n",
    "                colsample_bynode=0.8,\n",
    "                learning_rate=0.05,\n",
    "                subsample=0.8,\n",
    "            )\n",
    "        else:\n",
    "            model = LogisticRegression(\n",
    "                fit_intercept=True,\n",
    "                max_iter=1_500, \n",
    "                penalty=None,\n",
    "                random_state=42,\n",
    "        )\n",
    "\n",
    "        # cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        cv = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "        for train_index, test_index in cv.split(X, y):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        if class_to_weight == 'pos':\n",
    "            sample_weights = y_train.map({0: 1, 1: sample_w})\n",
    "        else:  \n",
    "            sample_weights = y_train.map({0: sample_w, 1: 1})\n",
    "        model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "        \n",
    "        if model_type == \"logistic\":\n",
    "            weights.append(model.coef_)\n",
    "        \n",
    "        probabilities = model.predict_proba(X_test)[:, 1]\n",
    "        logit_scores = logit(probabilities)\n",
    "        \n",
    "        pdo, odds, target_score = 20, 10, 600\n",
    "        if model_type == \"gbdt\":\n",
    "            pdo, odds, target_score = 20, 10, 1000\n",
    "        factor = pdo / np.log(2)\n",
    "        offset = target_score - factor * np.log(odds)\n",
    "        scores = -logit_scores * factor + offset        \n",
    "        scores -= scores.mean()\n",
    "        scores /= scores.std()\n",
    "        scores -= -6.5\n",
    "        scores *= 9\n",
    "\n",
    "        pos_logit = scores[y_test == 1]\n",
    "        neg_logit = scores[y_test == 0]\n",
    "\n",
    "        gini = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]) * 2 - 1\n",
    "        ks_statistic = ks_stat(y_test, model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "        _, ax1 = plt.subplots(1, 1, figsize=(8, 6))\n",
    "        \n",
    "        ax1.set_xlim(0, 100)\n",
    "        \n",
    "        common_kde_params = dict(\n",
    "            fill=True, alpha=0.6, linewidth=0.0, bw_method=2.0, bw_adjust=0.5\n",
    "        )\n",
    "        \n",
    "        ax1.spines[\"right\"].set_visible(False)\n",
    "        ax1.spines[\"top\"].set_visible(False)\n",
    "        \n",
    "        # add background color to the ax1\n",
    "        ax1.set_facecolor('white')\n",
    "        \n",
    "        ax1.tick_params(axis=\"x\", length=0)\n",
    "        ax1.tick_params(axis=\"y\", length=0)\n",
    "\n",
    "        sns.kdeplot(pos_logit, label=\"Not approved\", ax=ax1, color=\"#a801ff\", common_norm=True, **common_kde_params) # type: ignore\n",
    "        sns.kdeplot(neg_logit, label=\"Approved\", ax=ax1, color=\"#a7fe01\",common_norm=True, **common_kde_params) # type: ignore\n",
    "        \n",
    "        ax1.legend(fontsize=12)\n",
    "\n",
    "        ax1.set_xlabel(\"Credit score\")\n",
    "        ax1.set_ylabel(\"Density\")\n",
    "        ax1.set_title(f\"W = {sample_w:.4f}\")\n",
    "        \n",
    "        ax1.legend(title='Approval Status', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "        metrics_text = (\n",
    "            f\"Gini (CV) = {gini:.2%}\\n\"\n",
    "            f\"KS (CV) = {ks_statistic:.2%}\"\n",
    "        )\n",
    "\n",
    "        box_x_position = 0.05\n",
    "        box_y_position = 0.95\n",
    "\n",
    "        ax1.text(\n",
    "            box_x_position, box_y_position,\n",
    "            metrics_text, fontsize=12,\n",
    "            transform=ax1.transAxes,\n",
    "            horizontalalignment='left', verticalalignment='top',\n",
    "            bbox=dict(facecolor='white', alpha=0.5, edgecolor='gray', boxstyle='round,pad=0.5')\n",
    "        )\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight_vector = [1e-3, 1e-1, 1e-0, 1e1, 1e3, 1e5]\n",
    "# # sample_weight_vector = [1e-0]\n",
    "\n",
    "# # plot_densities(model, X.loc[ix_train], y.loc[ix_train], sample_weight_vector, model_type='logistic')\n",
    "plot_densities(model, X, y, sample_weight_vector, model_type='logistic', class_to_weight='neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "sample_weights = y.loc[ix_train].map({0: 0.001, 1: 1})\n",
    "\n",
    "model = LogisticRegression(fit_intercept=True, max_iter=1000, penalty=None, random_state=42)\n",
    "\n",
    "model.fit(X.loc[ix_train], y.loc[ix_train], sample_weight=sample_weights)\n",
    "\n",
    "preds = model.predict_proba(X.loc[ix_test])[:, 1]\n",
    "gini = roc_auc_score(y.loc[ix_test], preds) * 2 - 1\n",
    "print(f\"Gini: {gini:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight_vector = [1e-3, 1e-1, 1e-0, 1e1, 1e3, 1e5]\n",
    "\n",
    "plot_densities(model, X.loc[ix_train], y.loc[ix_train], sample_weight_vector, model_type='gbdt', class_to_weight='neg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pylab import f\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import ks_2samp\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "weights = []\n",
    "\n",
    "# style must be one of white, dark, whitegrid, darkgrid, ticks\n",
    "sns.set_style('white')\n",
    "\n",
    "def ks_stat(y, yhat):\n",
    "    return ks_2samp(yhat[y == 1], yhat[y != 1]).statistic  # type: ignore\n",
    "\n",
    "# monotonicity = (1, -1)\n",
    "monotonicity = (1, -1)\n",
    "def plot_decision_boundary(model, X, y, paired_features, sample_weight, model_type=\"logistic\"):\n",
    "    \n",
    "    fit_intercept_param = True\n",
    "\n",
    "    for sample_w in sample_weight:\n",
    "        \n",
    "        if model_type == \"gbdt\":\n",
    "            model = xgb.XGBClassifier(\n",
    "                n_estimators=300,\n",
    "                reg_lambda=2.0,\n",
    "                max_depth=2,\n",
    "                learning_rate=0.05,\n",
    "                subsample=0.6,\n",
    "                monotone_constraints=monotonicity,\n",
    "            )\n",
    "        else:\n",
    "            model = LogisticRegression(\n",
    "                fit_intercept=fit_intercept_param,\n",
    "                penalty='l2',\n",
    "                C=1.0,\n",
    "                max_iter=1000\n",
    "            )\n",
    "\n",
    "        sample_weights = np.where(y == 0, sample_w, 1)\n",
    "\n",
    "        # Fit model using only specified paired features\n",
    "        model.fit(X[paired_features], y, sample_weight=sample_weights)\n",
    "        \n",
    "        if model_type == \"logistic\":\n",
    "            weights.append(model.coef_)\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        # set colormap to cmap\n",
    "\n",
    "        feature_1, feature_2 = np.meshgrid(\n",
    "            np.linspace(X[paired_features[0]].min(), X[paired_features[0]].max()),\n",
    "            np.linspace(X[paired_features[1]].min(), X[paired_features[1]].max())\n",
    "        )\n",
    "\n",
    "        grid = np.vstack([feature_1.ravel(), feature_2.ravel()]).T\n",
    "\n",
    "        y_pred = np.reshape(\n",
    "            model.predict_proba(grid)[:, 1],\n",
    "            feature_1.shape\n",
    "        )\n",
    "        \n",
    "\n",
    "        display = DecisionBoundaryDisplay(\n",
    "            xx0=feature_1, \n",
    "            xx1=feature_2, \n",
    "            response=y_pred,\n",
    "        )\n",
    "\n",
    "        display.plot()\n",
    "        \n",
    "        scatter = display.ax_.scatter(\n",
    "            X[paired_features[0]], \n",
    "            X[paired_features[1]], \n",
    "            c=y,\n",
    "            edgecolors='k',\n",
    "            s=10,\n",
    "        )\n",
    "\n",
    "        unique_labels = np.unique(y)\n",
    "        for unique_label in unique_labels:\n",
    "            class_desc = 'Approved' if unique_label == 0 else 'Not Approved'\n",
    "            plt.scatter(\n",
    "                [], [], color=scatter.cmap(scatter.norm(unique_label)), label=f\"{class_desc}\" # type: ignore\n",
    "            )\n",
    "\n",
    "        # Place the legend outside the plot area\n",
    "        plt.legend(title=\"Approval Status\", loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "        # Calculate Gini index\n",
    "        gini = roc_auc_score(y, model.predict_proba(X[paired_features])[:, 1]) * 2 - 1\n",
    "        \n",
    "        plt.xlabel('Card usage')\n",
    "        plt.ylabel('% Days with positive balance')\n",
    "        \n",
    "        \n",
    "        if model_type == \"logistic\":\n",
    "            plt.suptitle(f'W = {sample_w:.4f}, Gini = {gini:.2%}', y=1.00)\n",
    "            plt.title(\n",
    "                f\"Weight 1 = {model.coef_.ravel()[0]:.2f}, \"\n",
    "                f\"Weight 2 = {model.coef_.ravel()[1]:.2f}\"\n",
    "                # if fit_intercept_param is true then show intercept value\n",
    "                f\", Bias = {model.intercept_[0]:.2f}\" if fit_intercept_param else \"\",\n",
    "            )\n",
    "        else:\n",
    "            plt.suptitle(f'W = {sample_w:.4f}, Gini = {gini:.2%}', y=1.00)\n",
    "            plt.title(\n",
    "                f\"Estimators = {model.n_estimators}, \"\n",
    "                f\"Max depth = {model.max_depth}, \"\n",
    "                f\"Monotonicity = {model.monotone_constraints}\"\n",
    "            )\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight_vector = [1e-3, 1e-1, 1e-0, 1e1, 1e3, 1e5]\n",
    "\n",
    "plot_decision_boundary(model, X.loc[ix_train], y.loc[ix_train], X.iloc[:,: 2].columns.tolist(), sample_weight_vector, model_type='gbdt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lr-focal-loss-Opjerf94-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
