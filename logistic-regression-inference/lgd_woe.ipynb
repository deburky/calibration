{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d408e153",
   "metadata": {},
   "source": [
    "# <center> LGD models </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3a1e6e",
   "metadata": {},
   "source": [
    "### WOE Logistic Regression LGD model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0281112f",
   "metadata": {},
   "source": [
    "**WoE transformation in LGD (Loss Given Default) model development**\n",
    "\n",
    "[![Python 3.11](https://img.shields.io/badge/Python-3.11-3776AB?logo=python&logoColor=white)](https://www.python.org/downloads/release/python-3110/)\n",
    "\n",
    "\n",
    "Author: https://github.com/deburky\n",
    "\n",
    "Implementation of the approach by A. van Berkel and N. Siddiqi: [Building Loss Given Default Scorecard Using Weight of Evidence Bins](https://support.sas.com/resources/papers/proceedings12/141-2012.pdf).\n",
    "\n",
    "Data is from B. Baesens' book, Credit Risk Analytics.\n",
    "\n",
    "The data set has been kindly provided by a European bank and has been slightly\n",
    "modified and anonymized. It includes 2,545 observations on loans and LGDs. Key\n",
    "variables are:\n",
    "* LTV: Loan-to-value ratio, in %\n",
    "* Recovery_rate: Recovery rate, in %\n",
    "* lgd_time: Loss rate given default (LGD), in %\n",
    "* y_logistic: Logistic transformation of the LGD\n",
    "* lnrr: Natural logarithm of the recovery rate\n",
    "* Y_probit: Probit transformation of the LGD\n",
    "* purpose1: Indicator variable for the purpose of the loan; 1 = renting purpose,\n",
    "0 = other\n",
    "*  event: Indicator variable for a default or cure event; 1 = event, 0 = no event\n",
    "<hlink> https://www.sas.com/storefront/aux/en/spcriskmdl/68835_excerpt.pdf </hlink>\n",
    "\n",
    "WoE transformation algorithm designed for the binary response can be directly applied to the new dataset with the converted LGD.\n",
    "<p>We use lightGBM to perform granular monotonic binning aimed at miminizing logistic loss.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b99b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flatdict\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12b05fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = (\n",
    "    \"https://raw.githubusercontent.com/deburky/calibration/\"\n",
    "    \"refs/heads/main/logistic-regression-inference/datasets/lgd_woe.csv\"\n",
    ")\n",
    "lgd = pd.read_csv(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8778455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_dataset(df, id_col):\n",
    "    lgd_woe = []\n",
    "    for i in df[id_col].unique():\n",
    "        mask = df[id_col] == i\n",
    "        df_bad = df[mask].loc[df[mask].index.repeat(df[mask].bads)]\n",
    "        df_bad[\"is_default\"] = 1\n",
    "        df_good = df[mask].loc[df[mask].index.repeat(df[mask].goods)]\n",
    "        df_good[\"is_default\"] = 0\n",
    "        df_all = pd.concat([df_bad, df_good], axis=0)\n",
    "        lgd_woe.append(df_all)\n",
    "    return pd.concat(lgd_woe)\n",
    "\n",
    "\n",
    "def calculate_woe(df, col, target_col):\n",
    "    \"\"\"\n",
    "    Calculate the Weight of Evidence (WOE) for a categorical variable.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas DataFrame): The dataframe containing the data.\n",
    "    col (str): The name of the categorical variable for which to calculate WOE.\n",
    "    target_col (str): The name of the target variable.\n",
    "\n",
    "    Returns:\n",
    "    pandas Series: A series containing the WOE values for each category of the variable.\n",
    "    \"\"\"\n",
    "    categories = df[col].unique()\n",
    "    woe_values = {}\n",
    "    for category in categories:\n",
    "        category_df = df[df[col] == category]\n",
    "\n",
    "        # bin counts\n",
    "        good_count_bin = category_df[category_df[target_col] == 0][target_col].count()\n",
    "        bad_count_bin = category_df[category_df[target_col] == 1][target_col].count()\n",
    "\n",
    "        # total counts\n",
    "        good_count = df[df[target_col] == 0][target_col].count()\n",
    "        bad_count = df[df[target_col] == 1][target_col].count()\n",
    "\n",
    "        # conditions\n",
    "        if good_count == 0 or bad_count == 0:\n",
    "            woe_values[category] = 0\n",
    "        elif good_count_bin == 0 or bad_count_bin == 0:\n",
    "            woe_values[category] = 0\n",
    "        else:\n",
    "            goods = good_count_bin / good_count\n",
    "            bads = bad_count_bin / bad_count\n",
    "            woe = np.log(goods / bads)\n",
    "            woe_values[category] = woe\n",
    "\n",
    "    return pd.Series(df[col].map(woe_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e864e2cb",
   "metadata": {},
   "source": [
    "### Dataset duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ff95c26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample: 254,500\n",
      "Duplicated sample: 25,450,000\n"
     ]
    }
   ],
   "source": [
    "lgd_woe = duplicate_dataset(lgd, \"id\")\n",
    "print(f\"Original sample: {len(lgd):,.0f}\")\n",
    "print(f\"Duplicated sample: {len(lgd_woe):,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c34558",
   "metadata": {},
   "source": [
    "### Logisic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75c8b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.98809619] [[0.78799966 2.27144465]]\n",
      "['purpose1_1' 'ltv']\n",
      "46.46%\n"
     ]
    }
   ],
   "source": [
    "# mirroring statsmodels logistic regression\n",
    "lr_params = {\n",
    "    \"fit_intercept\": True,\n",
    "    \"penalty\": None,\n",
    "    \"random_state\": 72,\n",
    "    \"solver\": \"newton-cg\",\n",
    "}\n",
    "\n",
    "X = lgd_woe[[\"ltv\", \"purpose1\"]]\n",
    "y = lgd_woe[\"is_default\"].values\n",
    "\n",
    "# splitting dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=True, random_state=62\n",
    ")\n",
    "\n",
    "categorical_features = [\"purpose1\"]\n",
    "\n",
    "# one-hot encoding categorical features\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"OneHotEncoder\",\n",
    "            OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"),\n",
    "            categorical_features,\n",
    "        )\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "\n",
    "# creating a pipeline\n",
    "sk_lr_model_ohe = make_pipeline(transformer, LogisticRegression(**lr_params))\n",
    "\n",
    "# training the model\n",
    "sk_lr_model_ohe.fit(X_train, y_train)\n",
    "print(sk_lr_model_ohe[1].intercept_, sk_lr_model_ohe[1].coef_)\n",
    "print(sk_lr_model_ohe[0].get_feature_names_out())\n",
    "\n",
    "# discrimination ability\n",
    "y_pred = sk_lr_model_ohe.predict_proba(X_test)[:, 1]\n",
    "gini = roc_auc_score(y_test, y_pred) * 2 - 1\n",
    "print(f\"{gini:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bad8dd2",
   "metadata": {},
   "source": [
    "### Univariate Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c10407d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.92685801] [[2.28102999]]\n",
      "Gini : 44.87%\n"
     ]
    }
   ],
   "source": [
    "X_train_ltv = X_train.loc[:, \"ltv\"].values.reshape(-1, 1)\n",
    "X_test_ltv = X_test.loc[:, \"ltv\"].values.reshape(-1, 1)\n",
    "\n",
    "# initializing LR class\n",
    "sk_lr_model = LogisticRegression(**lr_params)\n",
    "\n",
    "# training the model\n",
    "sk_lr_model.fit(X_train_ltv, y_train)\n",
    "print(sk_lr_model.intercept_, sk_lr_model.coef_)\n",
    "\n",
    "y_pred = sk_lr_model.predict_proba(X_test_ltv)[:, 1]\n",
    "\n",
    "gini = roc_auc_score(y_test, y_pred) * 2 - 1\n",
    "print(f\"Gini : {gini:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274e2795",
   "metadata": {},
   "source": [
    "### Binning with LightGBM\n",
    "<hlink>https://github.com/microsoft/LightGBM/issues/638</hlink>\n",
    "<p> Linearizing a tree into decision rules</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ae1f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin edges: [ -inf 0.046 0.195 0.349 0.432 0.604 0.61  0.687 0.69  0.749 0.792 0.795\n",
      " 0.845 0.917 0.933 0.94  0.965 1.069 1.096 1.124 1.313 1.495 1.964   inf]\n",
      "# of bins: 24\n",
      "Gini: 45.69%\n"
     ]
    }
   ],
   "source": [
    "X = lgd_woe[\"ltv\"].values.reshape(-1, 1)\n",
    "y = lgd_woe[\"is_default\"].values\n",
    "\n",
    "# splitting dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=True, random_state=62\n",
    ")\n",
    "\n",
    "# create datasets for LightGBM\n",
    "lgb_train = lgb.Dataset(X_train, y_train)  # params={\"max_bin\": 20}\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)  # params={\"max_bin\": 20}\n",
    "\n",
    "tree_params = {\n",
    "    \"boosting_type\": \"rf\",\n",
    "    \"max_depth\": 5,\n",
    "    \"objective\": \"binary\",\n",
    "    \"bagging_freq\": 1,\n",
    "    \"bagging_fraction\": 0.999,\n",
    "    \"feature_fraction\": 0.999,\n",
    "    \"bagging_seed\": 323,\n",
    "    \"verbosity\": -1,\n",
    "    \"monotone_constraints\": [1],\n",
    "}\n",
    "\n",
    "gbm = lgb.train(\n",
    "    params=tree_params, train_set=lgb_train, num_boost_round=5, valid_sets=lgb_eval\n",
    ")\n",
    "\n",
    "# gbm.save_model(\"gbm_model.txt\")\n",
    "\n",
    "tree_info = gbm.dump_model()[\"tree_info\"][0]\n",
    "d_tree_prop = flatdict.FlatDict(tree_info, delimiter=\".\")\n",
    "thresholds = [round(d_tree_prop[key], 3) for key in d_tree_prop if \"threshold\" in key]\n",
    "bin_edges = [-np.inf, *sorted(thresholds), np.inf]\n",
    "bin_edges = np.unique(bin_edges)\n",
    "\n",
    "print(f\"Bin edges: {bin_edges}\")\n",
    "print(f\"# of bins: {bin_edges.size}\")\n",
    "\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "gini = roc_auc_score(y_test, y_pred) * 2 - 1\n",
    "print(f\"Gini: {gini:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0449374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to bins\n",
    "lgd_woe[\"ltv_woe_bins\"] = np.digitize(lgd_woe[\"ltv\"], bin_edges)\n",
    "# create WOE features\n",
    "lgd_woe[\"ltv_woe\"] = calculate_woe(lgd_woe, \"ltv_woe_bins\", \"is_default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e5f383",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96386877",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgd_woe[\"lgd_proba\"] = gbm.predict(lgd_woe[[\"ltv_woe\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f7466",
   "metadata": {},
   "source": [
    "### Downturn LGD calibration\n",
    "The goal is to incorporate Downturn LGD into our calibrated predictions. <p> This is achieved by using an adjusted weight of non-defaulted observations to change average LGD in our calibration sample to match DT LGD.</p>\n",
    "<p> <b>Instead of repeating samples, re-weight the loss function.</b>\n",
    "Same effect as over-sampling (though not random), but not as expensive (dataset size the same).\n",
    "\n",
    "One way we can make the resampling more efficient is by using class weights instead of actually resampling. So we can change our loss function to do the same thing as if you would resample but under sampling case, we don’t actually throw away any data and in the oversampling case, we don’t actually make our computational problem harder by repeating some of the samples. This works for most models and it’s pretty simple to do in scikit-learn. Basically, it’s the same as oversampling in a sense because you’re not throwing away any data. - Source A. Mueller.<hlink> https://amueller.github.io/aml/05-advanced-topics/11-imbalanced-datasets.html#class-weights</hlink></p>\n",
    "<p> Already fitted classifiers can be calibrated via the parameterv`cv=\"prefit\"`. In this case, no cross-validation is used and all provided data is used for calibration. The user has to take care manually that data for model fitting and calibration are disjoint. - Source sklearn.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a696f5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGD sample: 22.80%\n",
      "LGD target: 24.63%\n",
      "Sample weight: 90.40%\n"
     ]
    }
   ],
   "source": [
    "# using weights for non-defaulted observations\n",
    "LGD_SAMPLE = np.mean(lgd_woe[\"is_default\"].values)\n",
    "DT_MULTIPLICATOR = 1.08  # LGD downturn multiplicator\n",
    "LGD_TARGET = LGD_SAMPLE * DT_MULTIPLICATOR\n",
    "WEIGHT = (LGD_SAMPLE * (1 - LGD_TARGET)) / (LGD_TARGET * (1 - LGD_SAMPLE))\n",
    "print(\n",
    "    f\"LGD sample: {LGD_SAMPLE:.2%}\\nLGD target: {LGD_TARGET:.2%}\\nSample weight: {WEIGHT:.2%}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "63211b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((1-LGD_TARGET) / LGD_TARGET) / ((1-LGD_SAMPLE) / LGD_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6b5108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22801178781925344 0.24625273084479374\n",
      "1.08 0.9763714746705621\n",
      "0.9040476617320019\n",
      "[-1.11724229] [[-0.99454606]]\n",
      "Average predicted probability: 24.39%\n"
     ]
    }
   ],
   "source": [
    "# King and Zeng (2001) - Weighting\n",
    "w1 = LGD_TARGET / LGD_SAMPLE\n",
    "w0 = (1 - LGD_TARGET) / (1 - LGD_SAMPLE)\n",
    "print(LGD_SAMPLE, LGD_TARGET)\n",
    "print(w1, w0)\n",
    "\n",
    "# weight for non-defaulted observations\n",
    "# 0.98/1.08 = 0.904\n",
    "print(w0 / w1)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=72)\n",
    "\n",
    "# weighted exogenous sampling maximum-likelihood estimator\n",
    "sk_lr_model_cw = LogisticRegressionCV(\n",
    "    fit_intercept=True,\n",
    "    cv=skf,\n",
    "    refit=False,\n",
    "    Cs=[1e-4],\n",
    "    intercept_scaling=0.1,\n",
    "    #     class_weight={0: w0, 1: w1}\n",
    "    class_weight={0: w0 / w1, 1: 1},\n",
    ")\n",
    "\n",
    "sk_lr_model_cw.fit(X_train, y_train)\n",
    "print(sk_lr_model_cw.intercept_, sk_lr_model_cw.coef_)\n",
    "\n",
    "y_pred = sk_lr_model_cw.predict_proba(X_test)[:, 1]\n",
    "print(f\"Average predicted probability: {y_pred.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "261a37f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.21801046] [[-0.9946171]]\n",
      "Average predicted probability: 22.81%\n",
      "Average predicted probability with prior: 24.39%\n"
     ]
    }
   ],
   "source": [
    "# King and Zeng (2001) - Prior correction\n",
    "sk_lr_model_cw = LogisticRegressionCV(cv=skf, refit=False)\n",
    "sk_lr_model_cw.fit(X_train, y_train)\n",
    "print(sk_lr_model_cw.intercept_, sk_lr_model_cw.coef_)\n",
    "\n",
    "y_pred = sk_lr_model_cw.predict_proba(X_test)[:, 1]\n",
    "print(f\"Average predicted probability: {y_pred.mean():.2%}\")\n",
    "\n",
    "# correcting the estimates based on prior information\n",
    "# MLE of β1 need not be changed, but the constant term should\n",
    "# be corrected by subtracting out the bias factor\n",
    "prior = np.log(((1 - LGD_TARGET) / LGD_TARGET) * (LGD_SAMPLE / (1 - LGD_SAMPLE)))\n",
    "# intercept_corr = -3.6522636 - prior # b0\n",
    "y_pred_logit = (\n",
    "    sk_lr_model_cw.intercept_ - prior + (X_train * sk_lr_model_cw.coef_).sum(axis=1)\n",
    ")\n",
    "# y_pred_logit_pc = y_pred_logit - prior # as in King's formula\n",
    "y_pred_pc = 1 / (1 + np.exp(-y_pred_logit))\n",
    "print(f\"Average predicted probability with prior: {y_pred_pc.mean():.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
